
Without the database work, (basically just doing URL fetching) 
The BuildIndices took 1059877 cycles and 35 seconds to run with just BBC world and Boston Globe. 
Observed that articles proceeded much faster than BBC. 
Also observed that it took a few seconds to get the first BBC article, and was subsequently faster. 

BBC World News (World Front Page): http://newsrss.bbc.co.uk/rss/newsonline_world_edition/front_page/rss.xml
Boston Globe National: https://www.boston.com/tag/national-news/?feed=rss


For those of you in need of a hash function for strings,
you can use the following, which is lifted from a textbook
we used to use in CS106A.  You'll need to modify it so that
it can be used by a hashset to store C strings (or structs
keyed on C strings).

/** 
 * StringHash                     
 * ----------  
 * This function adapted from Eric Roberts' "The Art and Science of C"
 * It takes a string and uses it to derive a hash code, which   
 * is an integer in the range [0, numBuckets).  The hash code is computed  
 * using a method called "linear congruence."  A similar function using this     
 * method is described on page 144 of Kernighan and Ritchie.  The choice of                                                     
 * the value for the kHashMultiplier can have a significant effect on the                            
 * performance of the algorithm, but not on its correctness.                                                    
 * This hash function has the additional feature of being case-insensitive,  
 * hashing "Peter Pawlowski" and "PETER PAWLOWSKI" to the same code.  
 */  

static const signed long kHashMultiplier = -1664117991L;
static int StringHash(const char *s, int numBuckets)  
{            
  int i;
  unsigned long hashcode = 0;
  
  for (i = 0; i < strlen(s); i++)  
    hashcode = hashcode * kHashMultiplier + tolower(s[i]);  
  
  return hashcode % numBuckets;                                
}
